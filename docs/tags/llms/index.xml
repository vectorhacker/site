<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Llms on Victor&#39;s Blog</title>
    <link>https://victoramartinez.com/tags/llms/</link>
    <description>Recent content in Llms on Victor&#39;s Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>Victor Martínez</copyright>
    <lastBuildDate>Sun, 25 May 2025 21:11:50 -0400</lastBuildDate>
    <atom:link href="https://victoramartinez.com/tags/llms/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Limits of Current AI: A Skeptical Perspective on Autonomous Agents</title>
      <link>https://victoramartinez.com/posts/limits-of-current-ai/</link>
      <pubDate>Sun, 25 May 2025 21:11:50 -0400</pubDate>
      <guid>https://victoramartinez.com/posts/limits-of-current-ai/</guid>
      <description>&lt;p&gt;I align with Yann LeCun&amp;rsquo;s camp on this matter. I don&amp;rsquo;t believe that LLMs and machine learning alone will lead us to human-level intelligence. Current models have demonstrated only very limited reasoning capabilities within specific domains—essentially following and recombining similar patterns they&amp;rsquo;ve ingested during training.&lt;/p&gt;&#xA;&lt;p&gt;If you follow computer scientist and AI researcher Subbarao Kambhampati, a professor at the School of Computing and Augmented Intelligence at ASU, he proposes and demonstrates that language models and reasoning models cannot plan effectively even in domains as simple as organizing blocks in a virtual world, let alone in more complex domains.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
